{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch import nn\n",
    "from calrank import *\n",
    "from video_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "f_type = 'gamma_nuclear' # options are: [gamma_nuclear | LNN | Logarithm | ETP | Geman | Laplace]\n",
    "lr = 200\n",
    "lam=10000\n",
    "f_gamma = 500\n",
    "f_lam = 1\n",
    "step = 500\n",
    "use_f = False\n",
    "\n",
    "num_inv = 200\n",
    "num_g = 10000\n",
    "n = 5000\n",
    "grad_mask = True\n",
    "update_lr = True\n",
    "lr_change_step = 400\n",
    "lr_change_rate = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training Process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (198, 130, 160, 3)\n",
      "truncat shape: (100, 130, 160, 3)\n",
      "input shape: (100, 20800)\n",
      "w.device: cuda:0\n",
      "w.shape torch.Size([100, 20800])\n",
      "0 l1: tensor(0., device='cuda:0') l2: tensor(512781.5000, device='cuda:0') l: tensor(512781.5000, device='cuda:0')\n",
      "20 l1: tensor(287168.2812, device='cuda:0') l2: tensor(635059.5625, device='cuda:0') l: tensor(922227.8750, device='cuda:0')\n",
      "40 l1: tensor(172673., device='cuda:0') l2: tensor(472439.5000, device='cuda:0') l: tensor(645112.5000, device='cuda:0')\n",
      "60 l1: tensor(152495.1406, device='cuda:0') l2: tensor(451643.3750, device='cuda:0') l: tensor(604138.5000, device='cuda:0')\n",
      "80 l1: tensor(149562.1875, device='cuda:0') l2: tensor(448195.4062, device='cuda:0') l: tensor(597757.6250, device='cuda:0')\n",
      "100 l1: tensor(150569.1562, device='cuda:0') l2: tensor(442706.1562, device='cuda:0') l: tensor(593275.3125, device='cuda:0')\n",
      "120 l1: tensor(151499.5625, device='cuda:0') l2: tensor(440883.0938, device='cuda:0') l: tensor(592382.6250, device='cuda:0')\n",
      "140 l1: tensor(152395.6094, device='cuda:0') l2: tensor(446836.1250, device='cuda:0') l: tensor(599231.7500, device='cuda:0')\n",
      "160 l1: tensor(153981.8125, device='cuda:0') l2: tensor(447798.1562, device='cuda:0') l: tensor(601780., device='cuda:0')\n",
      "180 l1: tensor(154056.4844, device='cuda:0') l2: tensor(443972.3438, device='cuda:0') l: tensor(598028.8125, device='cuda:0')\n",
      "200 l1: tensor(154182.4844, device='cuda:0') l2: tensor(449179.6250, device='cuda:0') l: tensor(603362.1250, device='cuda:0')\n",
      "220 l1: tensor(155364.9062, device='cuda:0') l2: tensor(447013., device='cuda:0') l: tensor(602377.8750, device='cuda:0')\n",
      "240 l1: tensor(155318.5469, device='cuda:0') l2: tensor(447339.6562, device='cuda:0') l: tensor(602658.1875, device='cuda:0')\n",
      "260 l1: tensor(155828.6719, device='cuda:0') l2: tensor(447536.3125, device='cuda:0') l: tensor(603365., device='cuda:0')\n",
      "280 l1: tensor(156133.1719, device='cuda:0') l2: tensor(450509.3125, device='cuda:0') l: tensor(606642.5000, device='cuda:0')\n",
      "300 l1: tensor(156554.0938, device='cuda:0') l2: tensor(441795.9688, device='cuda:0') l: tensor(598350.0625, device='cuda:0')\n",
      "320 l1: tensor(156649.6875, device='cuda:0') l2: tensor(447090.2812, device='cuda:0') l: tensor(603740., device='cuda:0')\n",
      "340 l1: tensor(156863.8125, device='cuda:0') l2: tensor(445963.8750, device='cuda:0') l: tensor(602827.6875, device='cuda:0')\n",
      "360 l1: tensor(156871.4062, device='cuda:0') l2: tensor(444187.0312, device='cuda:0') l: tensor(601058.4375, device='cuda:0')\n",
      "380 l1: tensor(157156.4375, device='cuda:0') l2: tensor(446672.8750, device='cuda:0') l: tensor(603829.3125, device='cuda:0')\n",
      "400 l1: tensor(157115.8906, device='cuda:0') l2: tensor(444585.8750, device='cuda:0') l: tensor(601701.7500, device='cuda:0')\n",
      "420 l1: tensor(108383.9531, device='cuda:0') l2: tensor(413110.5312, device='cuda:0') l: tensor(521494.5000, device='cuda:0')\n",
      "440 l1: tensor(105916.8828, device='cuda:0') l2: tensor(412944., device='cuda:0') l: tensor(518860.8750, device='cuda:0')\n",
      "460 l1: tensor(108636.8438, device='cuda:0') l2: tensor(413364.1250, device='cuda:0') l: tensor(522000.9688, device='cuda:0')\n",
      "480 l1: tensor(108121.8516, device='cuda:0') l2: tensor(408592., device='cuda:0') l: tensor(516713.8438, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "video_input_path = r'escalator.avi'\n",
    "video_output_path = r'escalator_out.avi'\n",
    "\n",
    "# read the video and convert it into a N*W*H*C numpy array\n",
    "video_np_array = video_to_numpy_array(video_input_path)\n",
    "print('original shape:', video_np_array.shape)\n",
    "# only use first 100 frames, due to memory reason\n",
    "video_np_array = video_np_array[:100, :, :]\n",
    "print('truncat shape:', video_np_array.shape)\n",
    "input = video_np_array[...,0]\n",
    "frame_num = input.shape[0]\n",
    "input = input.reshape(frame_num,-1)\n",
    "input = video_np_array[...,0]\n",
    "frame_num = input.shape[0]\n",
    "input = input.reshape(frame_num,-1)\n",
    "if use_f:\n",
    "    input = input/255.0\n",
    "print('input shape:', input.shape)\n",
    "\n",
    "\n",
    "gpu = try_gpu(0)\n",
    "target = torch.tensor(input,requires_grad=False,dtype=torch.float32,device=gpu)\n",
    "w = torch.tensor(input,requires_grad=True,dtype=torch.float32,device=gpu)\n",
    "loss = nn.L1Loss(reduction='none')\n",
    "print(\"w.device:\",w.device)\n",
    "print(\"w.shape\",w.shape)\n",
    "# gamma_nuclear | LNN | Logarithm | ETP | Geman | Laplace\n",
    "if f_type == 'gamma_nuclear':\n",
    "    parameters = parameters_gamma_nuclear_norm(gamma=f_gamma,lam=f_lam)\n",
    "elif f_type == 'LNN':\n",
    "    parameters = parameters_LNN(lam=f_lam)\n",
    "elif f_type == 'Geman':\n",
    "    parameters = parameters_Geman(gamma=f_gamma,lam=f_lam)\n",
    "elif f_type == 'Laplace':\n",
    "    parameters = parameters_Laplace(gamma=f_gamma,lam=f_lam)\n",
    "elif f_type == 'ETP':\n",
    "    parameters = parameters_ETP(gamma=f_gamma,lam=f_lam)\n",
    "\n",
    "optimizer = torch.optim.Adam([w], lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_change_step, gamma=lr_change_rate)\n",
    "for i in range(step):\n",
    "    optimizer.zero_grad()\n",
    "    l1 = (loss(target, w)).sum()\n",
    "    non_zero_elements = input.shape[0] * input.shape[1]\n",
    "    l1 = lam * l1 / non_zero_elements\n",
    "    if use_f:\n",
    "        l2 = cal_rank_f(w,parameters=parameters,num_inv=num_inv,num_g=num_g,gpu=gpu,n=n)\n",
    "    else:\n",
    "        l2 = cal_rank_nuclear(w,num_inv=num_inv,num_g=num_g,gpu=gpu,n=n)\n",
    "    l = l1 + l2\n",
    "    if i%20==0:\n",
    "        print(i,\"l1:\",l1.data,\"l2:\",l2.data,\"l:\",l.data)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    if update_lr:\n",
    "        scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Saving results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "save_video(video_np_array, w.cpu().detach().numpy(), \"\", '%s_result.avi'%('escalator'), use_f)\n",
    "save_video(video_np_array, (target-w).cpu().detach().numpy(), \"\", '%s_residual_result.avi'%('escalator'),residual=True, use_f=use_f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}